# -*- coding: utf-8 -*-
"""DigitalExposome.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14IkDmr2MYatZ_7qK-6tdSBX4kVSLnxX_

# DigitalExposome: Wellbeing Sınıflandırması
Bu çalışma, çevresel hava kalitesi ve insan fizyolojik verilerine dayanarak bireylerin "wellbeing" (iyi oluş) seviyelerini sınıflandırmayı hedefler. Modelleme süreci Python ve scikit-learn kütüphaneleri ile gerçekleştirilmiştir.

## 1. Verinin Yüklenmesi
CSV formatındaki veriseti yüklenir ve ilk satırlar incelenerek sütun yapısı ve veri örnekleri gözlemlenir.
"""

# Kütüphaneler import edilir
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# Verisetini yükle
df = pd.read_csv("DigitalExposome Dataset.csv")
df.head()

# Eksik değer kontrolü
print(df.isnull().sum())

"""## 2. Etiket Dağılımının Görselleştirilmesi
Verisetindeki 'Label' sütunundaki değerlerin frekansı hesaplanır ve görselleştirilerek sınıf dengesizliği olup olmadığı analiz edilir.

"""

# Etiket dağılımını görselleştirmek için fonksiyon
def ShowLabelCounts():
    label_counts = df['Label'].value_counts()
    labels = label_counts.index
    counts = label_counts.values

    # Grafik boyutu ve çubuk grafiği oluştur
    plt.figure(figsize=(9, 6))
    bars = plt.bar(labels, counts, color='skyblue')

    # Başlık ve eksen etiketleri
    plt.title('Label Distribution', fontsize=14, weight='bold')
    plt.xlabel('Label', fontsize=13)
    plt.ylabel('Count', fontsize=13)

    # Çubukların üzerine sayıları yaz
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2,
                 height + (max(counts) * 0.01),
                 f'{int(height)}', ha='center', va='bottom', fontsize=11)

    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    plt.show()

# Fonksiyonu çağır
ShowLabelCounts()

"""## 3. Özelliklerin ve Etiketlerin Ayrılması
Tahmin edilecek etiket (y) ile özellikler (x) ayrılır. Daha sonra veri eğitim ve test setlerine bölünür.

"""

# Verisetini y (tahmin edilecek label değeri) ve x (tahmin etmek için kullanılacak parametreler) olarak ayır.
y = df.iloc[:, 8:9]
x = df.drop(y, axis=1)

# Verisetini train ve test olarak ayır.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=17)

print("Train DataSet\n-----------------------------------------------------")
print(y_train['Label'].value_counts())
print("\n------------------------------------------------------\nTest DataSet\n------------------------------------------------------")
print(y_test['Label'].value_counts())

"""## 4. Random Forest ile Model Eğitimi
Random Forest algoritması kullanılarak model oluşturulur ve eğitim verisi ile eğitilir.

"""

# Random Forest Classifier Modeli uygula
from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=10, criterion="entropy")
rfc.fit(x_train, y_train)

# Test veriseti üzerinde tahmin yap
y_pred = rfc.predict(x_test)
rfc.score(x_test, y_test)

"""## 5. Sınıflandırma Performansının Görselleştirilmesi
Precision, recall ve f1-score metrikleri her sınıf için hesaplanarak ısı haritası şeklinde görselleştirilir.

"""

# Raporu al
from sklearn.metrics import classification_report
report = classification_report(y_test, y_pred, output_dict=True)
print(classification_report(y_test, y_pred))

# Pandas DataFrame'e çevir
df_report = pd.DataFrame(report).transpose()

# Sadece sınıfları filtrele (accuracy, macro avg, vs. hariç)
df_filtered = df_report.iloc[:-3, :]

# Görselleştir
plt.figure(figsize=(10, 6))
sns.heatmap(df_filtered[['precision', 'recall', 'f1-score']], annot=True, cmap="Blues", fmt=".2f")
plt.title("Classification Report Heatmap")
plt.ylabel("Classes")
plt.xlabel("Metrics")
plt.tight_layout()
plt.show()

"""## 6. Bireysel Tahmin İncelemesi
Test setinden bir örnek seçilerek modelin tahmin ettiği sınıf ile gerçek sınıf karşılaştırılır.

"""

sample = x_test.iloc[1010]
sample_reshaped = sample.values.reshape(1, -1)
prediction = rfc.predict(sample_reshaped)

print("Tahmin edilen sınıf:", prediction[0])
print("Gerçek sınıf:", y_test.iloc[1010, 0])

"""## 7. Confusion Matrix (Karışıklık Matrisi)
Modelin hangi sınıfları ne kadar doğru veya hatalı tahmin ettiğini gösterir. Görsel analiz için ısı haritası şeklinde sunulur.

"""

# Confusion matrix hesapla
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Sınıf isimlerini belirle
class_names = ['1', '2','3','4','5']

# Görselleştir
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

"""## 8. ROC Eğrileri ile Sınıf Bazlı AUC Analizi
Çoklu sınıflandırma problemi için ROC eğrileri her bir sınıf için çizilir. Her bir sınıfın AUC (Area Under Curve) değeri görsel olarak sunulur.

"""

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import RocCurveDisplay

# Etiketleri binarize et (One-hot encoding)
y_test_bin = label_binarize(y_test, classes=[1, 2, 3, 4, 5])
n_classes = y_test_bin.shape[1]

# Yeni model tanımlayıp eğit (pipeline ile birlikte - ROC için ihtiyaç duyulur)
model = make_pipeline(StandardScaler(), OneVsRestClassifier(RandomForestClassifier(n_estimators=10, criterion="entropy")))
model.fit(x_train, label_binarize(y_train, classes=[1, 2, 3, 4, 5]))

# Skorları al
y_score = model.predict_proba(x_test)

# ROC eğrileri için ayar
fpr = dict()
tpr = dict()
roc_auc = dict()

# Her sınıf için ROC eğrisi hesapla
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Tüm sınıflar için ROC eğrilerini çiz
plt.figure(figsize=(10, 8))
colors = ['blue', 'green', 'orange', 'red', 'purple']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Sınıf {i+1} (AUC = {roc_auc[i]:0.2f})')

# Referans (şans) eğrisi
plt.plot([0, 1], [0, 1], 'k--', lw=2)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=13)
plt.ylabel('True Positive Rate', fontsize=13)
plt.title('ROC Curves for Multi-Class Classification', fontsize=15, weight='bold')
plt.legend(loc="lower right", fontsize=12)
plt.grid(True)
plt.tight_layout()
plt.show()

"""## 9. Diğer Sınıflandırma Yöntemleri

### I. Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

# Modeli oluştur ve eğit
model = LogisticRegression()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)

# Doğruluk ve diğer metrikler
report = classification_report(y_test, y_pred, output_dict=True)
print(classification_report(y_test, y_pred))

"""### II. Decision Tree


"""

from sklearn.tree import DecisionTreeClassifier

# Modeli oluştur ve eğit
model = DecisionTreeClassifier(criterion="entropy", random_state=42)
model.fit(x_train, y_train)

y_pred = model.predict(x_test)

# Doğruluk ve diğer metrikler
report = classification_report(y_test, y_pred, output_dict=True)
print(classification_report(y_test, y_pred))

"""### III. Support Vector Machine



"""

from sklearn.svm import SVC

# SVM modelini oluşturma ve eğitme
svm_model = SVC(kernel='linear', C=1)
svm_model.fit(x_train, y_train)

y_pred = svm_model.predict(x_test)

# Doğruluk ve diğer metrikler
report = classification_report(y_test, y_pred, output_dict=True)
print(classification_report(y_test, y_pred))

"""### IV. Gaussian Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

# Modeli oluştur ve eğit
gnb = GaussianNB()
gnb.fit(x_train, y_train)

y_pred = gnb.predict(x_test)

# Doğruluk ve diğer metrikler
report = classification_report(y_test, y_pred, output_dict=True)
print(classification_report(y_test, y_pred))